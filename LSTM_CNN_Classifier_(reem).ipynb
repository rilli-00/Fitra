{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rilli-00/Fitra/blob/main/LSTM_CNN_Classifier_(reem).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PzNnO5Tuus7"
      },
      "source": [
        "#**LSTM-CNN-Classifier**\n",
        "This model combines CNN and LSTM to take advantage of their strengths. CNN extracts important features from the text, such as patterns and key words. Then, LSTM captures the sequence and context between words. This combination helps the model analyze text more effectively and achieve higher classification accuracy\n",
        "\n",
        " Benefits of Combining CNN + LSTM in a Model:\n",
        "\n",
        "1️⃣ Feature Extraction & Pattern Recognition (CNN)\n",
        "\n",
        "CNN efficiently extracts key features from textual data.\n",
        "Captures spatial relationships between words, even if order is less important.\n",
        "Reduces dimensionality while preserving important contextual patterns.\n",
        "\n",
        "2️⃣ Context Understanding & Sequential Learning (LSTM)\n",
        "\n",
        "LSTM focuses on the sequential nature of text.\n",
        "Maintains long-term dependencies, ensuring meaning is retained across sentences.\n",
        "Handles varying sequence lengths without losing important context.\n",
        "\n",
        "3️⃣ Improved Accuracy & Generalization\n",
        "\n",
        "CNN removes irrelevant noise, while LSTM refines contextual understanding.\n",
        "The combination enhances classification accuracy for complex text data.\n",
        "Prevents overfitting, making the model more robust.\n",
        "\n",
        "4️⃣ Balanced Speed & Efficiency\n",
        "\n",
        "CNN accelerates feature extraction, reducing processing time.\n",
        "LSTM ensures comprehensive text understanding, improving prediction quality.\n",
        "Together, they create a balanced trade-off between speed and depth.\n",
        "\n",
        "5️⃣ Better Performance on NLP Tasks\n",
        "\n",
        "Works well for text classification, sentiment analysis, and speech recognition.\n",
        "Handles context-sensitive tasks better than standalone CNN or LSTM.\n",
        "Effective for multilingual processing and complex sentence structures."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhyfigNOFTj6",
        "outputId": "612f06d2-678c-45d8-de7b-fb7fcda2335c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugQ-sXrIFp-X",
        "outputId": "7a27b1a7-83a8-46b7-beec-f2d16a7e6ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PnGjjfOLsgM"
      },
      "source": [
        "##Upload and clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "MXB-WLiXHsO9",
        "outputId": "7bf3d23f-6cd2-4955-8bae-57d4a953654d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43215f79-dcef-4bee-9833-f226f11a6fa3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43215f79-dcef-4bee-9833-f226f11a6fa3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combined_final_data.csv to combined_final_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-a91737bd5442>:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"contain_lgbtq\"] = df[\"contain_lgbtq\"].replace({\"yes\": 1, \"no\": 0})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 **Cleaned dataset saved at:** Cleaned_Dataset.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      video_id                                        video_title  \\\n",
              "0  O61aMY3Tqfk  q news tonight broadcast full tue jun q news t...   \n",
              "1  oCfIxCbogn4  thu feb daily live lgbtq news broadcast queer ...   \n",
              "2  CqcXXaCoJis  wed feb daily live lgbtq news broadcast queer ...   \n",
              "3  8761Y_g3_go  tue feb daily live lgbtq news broadcast queer ...   \n",
              "4  OF_Wf2dVJ2M  mon feb daily live lgbtq news broadcast queer ...   \n",
              "\n",
              "                                           url  \\\n",
              "0  https://www.youtube.com/watch?v=O61aMY3Tqfk   \n",
              "1  https://www.youtube.com/watch?v=oCfIxCbogn4   \n",
              "2  https://www.youtube.com/watch?v=CqcXXaCoJis   \n",
              "3  https://www.youtube.com/watch?v=8761Y_g3_go   \n",
              "4  https://www.youtube.com/watch?v=OF_Wf2dVJ2M   \n",
              "\n",
              "                                   video_description  \\\n",
              "0  tune in daily for q news tonight live at pm ea...   \n",
              "1  we need your support become a patron missed ou...   \n",
              "2  we need your support become a patron missed ou...   \n",
              "3  we need your support become a patron missed ou...   \n",
              "4  we need your support become a patron missed ou...   \n",
              "\n",
              "                                          transcript  contain_lgbtq  \n",
              "0  well good evening america it is pm tuesday jun...              1  \n",
              "1  on oneill is our lead tonight who is dwight oh...              1  \n",
              "2  a comedian with us tonight and a tarot yeah th...              1  \n",
              "3  at least that happening out that both of you h...              1  \n",
              "4  presidents day presidents day were in life oka...              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-860e530b-bd27-45c8-bd1a-6abf35a55100\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>video_title</th>\n",
              "      <th>url</th>\n",
              "      <th>video_description</th>\n",
              "      <th>transcript</th>\n",
              "      <th>contain_lgbtq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O61aMY3Tqfk</td>\n",
              "      <td>q news tonight broadcast full tue jun q news t...</td>\n",
              "      <td>https://www.youtube.com/watch?v=O61aMY3Tqfk</td>\n",
              "      <td>tune in daily for q news tonight live at pm ea...</td>\n",
              "      <td>well good evening america it is pm tuesday jun...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oCfIxCbogn4</td>\n",
              "      <td>thu feb daily live lgbtq news broadcast queer ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=oCfIxCbogn4</td>\n",
              "      <td>we need your support become a patron missed ou...</td>\n",
              "      <td>on oneill is our lead tonight who is dwight oh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CqcXXaCoJis</td>\n",
              "      <td>wed feb daily live lgbtq news broadcast queer ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=CqcXXaCoJis</td>\n",
              "      <td>we need your support become a patron missed ou...</td>\n",
              "      <td>a comedian with us tonight and a tarot yeah th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8761Y_g3_go</td>\n",
              "      <td>tue feb daily live lgbtq news broadcast queer ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=8761Y_g3_go</td>\n",
              "      <td>we need your support become a patron missed ou...</td>\n",
              "      <td>at least that happening out that both of you h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OF_Wf2dVJ2M</td>\n",
              "      <td>mon feb daily live lgbtq news broadcast queer ...</td>\n",
              "      <td>https://www.youtube.com/watch?v=OF_Wf2dVJ2M</td>\n",
              "      <td>we need your support become a patron missed ou...</td>\n",
              "      <td>presidents day presidents day were in life oka...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-860e530b-bd27-45c8-bd1a-6abf35a55100')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-860e530b-bd27-45c8-bd1a-6abf35a55100 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-860e530b-bd27-45c8-bd1a-6abf35a55100');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb4ee132-1879-4be5-9c2d-681bec6384e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb4ee132-1879-4be5-9c2d-681bec6384e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb4ee132-1879-4be5-9c2d-681bec6384e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14404,\n  \"fields\": [\n    {\n      \"column\": \"video_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13904,\n        \"samples\": [\n          \"7TEKiI7aZTc\",\n          \"mpYKsZzkmHI\",\n          \"EUDJMFjn3Gg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12319,\n        \"samples\": [\n          \"oh canada as hamburger marys closes and the well is born on wilton drive\",\n          \"tucker carlson claims afghan people welcomed taliban to reject radical gender equality\",\n          \"here are special pictures of wives miss puerto rico miss argentina fabiola valentn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13904,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=7TEKiI7aZTc\",\n          \"https://www.youtube.com/watch?v=mpYKsZzkmHI\",\n          \"https://www.youtube.com/watch?v=EUDJMFjn3Gg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12845,\n        \"samples\": [\n          \"hotspots magazine and the happening out television network have partnered with pride fort lauderdale and the city of wilton manors to bring an lgbtq caribbean pride festival back to the island city the newly branded pridefte takes its name after a recognizable french word in the carnival community meaning party the authentic caribbean fest will represent the heart of carnival culture while set in the heartland of south floridas premier lgbtq destination wilton manors two elements rarely ever infused together\",\n          \"watch bluey full episodes abc kids australia available on disney junior and disney cbeebies uk subscribe to bluey at play with bingo and the christmas lights shorts join bluey bingo bandit and chilli on all their adventures more about bluey welcome to the official youtube channel for bluey bluey is a lovable and energetic blue heeler puppy who lives with her mum dad and little sister bingo she uses her limitless energy and imagination to discover laugh and play with all of her friends and family subscribe for all the latest from bluey created by ludo studio ludo studio website twitter instagram facebook this is a commercial channel from bbc studios\",\n          \"get to know the story of palmares an autonomous settlement founded by people escaping slavery in brazil in the s in the s an expansive autonomous settlement called palmares reached its height in brazil it was founded and led by people escaping from slavery also called maroons it was one of the worlds largest maroon communities its population reaching beyond and its citizens were at constant war with colonial forces marc adam hertzman flavio dos santos gomes tell the story of palmares lesson by marc adam hertzman flavio dos santos gomes directed by mateus moretto visorama support our nonprofit mission support us on patreon check out our merch connect with us sign up for our newsletter follow us on facebook find us on twitter peep us on instagram keep learning view full lesson dig deeper with additional resources animators website music thank you so much to our patrons for your support without you this video would not be possible michelange hortegat enes kirimi amaury bisiaux nd samyogita hardikar vanessa graulich vandana gunwani abdulmohsin almadi aj lyon geoffrey bultitude mi mi thomas rothert brian elieson oge o weronika falkowska nevin spoljaric sid chanpuriya anoop varghese david yastremski noah webb roberto chena oliver koo luke pisano andrea gordon aleksandar donev nicole klau ibarra jesse lira ezekiel raui petr vacek dennis olivia fu kari teffeau cindy lai rajath durgada manjunath dan nguyen chin beng tan tom boman karen warner iryna panasiuk aaron torres eric braun sonja worzewski michael clement adam berry ghaith tarawneh nathan milford tomas beckett alice ice eric berman and kurt paolo sevillano\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transcript\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13689,\n        \"samples\": [\n          \"the dawn and the train are both breaking when ethic and hedge arrive in the woods the adventurers have recovered the first artifact the note of power and have come to the forest in search of the second here theyre welcomed by the director of the colony octavia she established this tree house sanctuary after the robots freed everyone from having to work it was meant to be a haven where people could follow their passions take up crafts and find fulfillment which they did at first some years ago everyone forgot the point they abandoned arts and crafts and instead just painted and exhibited pictures of themselves over and over and over the location of the second artifact is no secret its in a tower guarded by a garrison of bots a bottomless ravine and who knows what other traps as soon as the tower went up with the note inside human communication across the land went dark octavia has been after it for years but tries she might the defenses for her in order to even get to the tower the team will need a distraction octavia has an idea stir up the people through some wellintentioned vandalism the residents paintings are all squares that come in different sizes all an odd number of pixels across helper bots pick up the finished portraits and hang them in public places for everyone to admire theres a slim margin of time when hedge can access the paintings if he were to deface each one with an axe the people would blame the helper bots creating just the distraction the team needs if only it were so easy hedge cant just paint an axe his painting processor requires very specific instructions treating the paintings as square grids he can fill in one pixel or little square at a time he can move forwards and make degree turns over the canvas but cant move diagonally how does ethic program hedge to paint an axe over each portrait heres a hint try drawing a square grid like this and simulating hedges path over it what patterns can you find to guide him the challenge here is to craft a set of instructions that will work for any square grid fortunately one of the strengths of programming is the flexibility to solve not just one problem but a whole class of them all at once it often helps to start with one case and work towards the general lets say we had this square hedge can measure the length of its sides and store that number as a variable now what we need is a plan for how hedge will paint an axe pixel by pixel theres more than one right answer for how to do this lets look at two first what if hedge went row by row like a typewriter if its a nine pixel by nine pixel painting in the first row hed paint skip seven and then paint again in the second row hed skip the first paint skip five and paint and so on the pattern here is that for each row the pixels skipped at the beginning go up by one and the pixels skipped in the middle go down by two things get more complicated when hedge reaches the center here theres a row with just one pixel painted then the whole thing reverses the number of pixels skipped goes down by one each time on the left and up by two each time in the middle instructing hedge to do this with a series of loops will work and is a perfectly fine solution the main drawback is that this requires quite a bit of logic knowing what to do in the middle when to reverse the process and exactly how to reverse it so how might we approach this so that the logic remains consistent from start to finish the key insight is to look at a grid as a series of concentric squares each square follows the same pattern painted pixels in the corners and unaltered pixels in between so if we can figure out a way to paint one nested square transition to the next and repeat we can paint them all painting the outermost one is easy start in the corner and paint that pixel if we call the length of the painting n fly forward n minus one spaces paint another pixel and turn right now do the whole thing again and again now move forward one last space turn right fly forward once and hedge will be in the next concentric square and ready to repeat the whole process each square is n minus two pixels smaller than the last in length and width and we can follow this spiral pattern all the way to the center with a loop and a variable that tracks how far hedge should fly is one of these methods better than the other it really depends on what you value the strength of the spiral is the simplicity of finding a pattern and reusing the same logic from start to finish the advantage of the typewriter approach is that its a more generalized solution meaning it can be adapted much more simply to fill in any pattern for ethics sake either will do just fine so heres what happens the drapidly defaces all of the portraits and within moments rise of anguish break out all over the forest the garrison guarding the tower abandon their posts to calm the agitated people and ethic hedge and octavia slip through and nearly slip into the depths of the gorge standing between them and the tower can you the adventure in episode of think like a coder or restart the journey with episode and dont forget to subscribe\",\n          \"next lets queer up south florida and florida floater rama celebrates the sights and lights of the holidays with december crews a delightful evening of live music and open bar heavy or derves and camaraderie all while taking in the mesmerizing holiday lights on the water this and morowayu on sights and lights evening crews by floater rama on december th the foot yacht caprice from sun dream yots will provide the perfect setting with elegant accommodations on three spacious decks it is surely something you would not want to miss the farm will begin at pm once you will board the crews at gallery hotel during this elegant hour event you will cruise the venice of america waterways in style with amazing views of the waterfront mansions and their holiday lights this is also an opportunity to mix and mingle with floater rama founders club members and supporters special presale tickets are up for sale already at per person if you miss this opportunity you will have to purchase regular tickets at per person from the st of november if you wish to set the new year mood right you must be on this floater rama cruise proceeds the cruise will benefit the floater rama lgbtq youth fund managed by the our fund foundation and directed by floater rama by floater rama floater rama has recently raised for the floater rama lgbtq youth fund further details about the cruise floater rama and ticket purchase are available in floater ramaorg well this is another fabulous event and a wonderful way to continue the feeling of the holidays in a beautiful setting i mean ive been on some yachts for this kind of touring thing and the mentions are fabulous to look at so im sure that for the holidays they will be really all dolled up they always are right for the holidays perfect and how fabulous this is its just fabulous you get to be on a boat and look at all the houses youll never afford i mean like its so much fun beautiful and the folks of our floater rama you know how to throw a party and they just really do scotchram rod his whole entire crew over there you know and they do it with the vision to help other organizations at the tail end of it and thats why i love floater rama and everything that they do and i will be on this boat right because i mean what do you wear on a boat trip like this like a big hat or like you could dress like mrs howell from gilligans island oh my god im totally good right oh my god its going to be so much fun and dont forget get your tickets early because because its a boat ride its limited amount floater rama is not going to squish you with people on a small boat theyre going to do and thats it okay so get your tickets quick because its going to sell out for sure\",\n          \"and this is a silhouette of a dog dog dogs are humans best friend dog\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contain_lgbtq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "#load data\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(list(uploaded.keys())[0])\n",
        "\n",
        "#cleaning method\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "df[\"video_title\"] = df[\"video_title\"].apply(clean_text)\n",
        "df[\"video_description\"] = df[\"video_description\"].apply(clean_text)\n",
        "df[\"transcript\"] = df[\"transcript\"].apply(clean_text)\n",
        "\n",
        "#  clean contain_lgbtq`\n",
        "df[\"contain_lgbtq\"] = df[\"contain_lgbtq\"].astype(str).str.strip().str.lower()\n",
        "df[\"contain_lgbtq\"] = df[\"contain_lgbtq\"].replace({\"yes\": 1, \"no\": 0})\n",
        "df = df[df[\"contain_lgbtq\"].isin([0, 1])]\n",
        "\n",
        "\n",
        "#remove empty data\n",
        "df = df.dropna(subset=[\"video_title\"])\n",
        "df = df.dropna(subset=[\"video_description\"])\n",
        "df = df.dropna(subset=[\"transcript\"])\n",
        "\n",
        "\n",
        "\n",
        "# save after cleaning\n",
        "cleaned_file_path = \"Cleaned_Dataset.csv\"\n",
        "df.to_csv(cleaned_file_path, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n📂 **Cleaned dataset saved at:** {cleaned_file_path}\")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-VWWq5gLzlU"
      },
      "source": [
        "##Text Embedding with FastText\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWMXFzmOMOhA",
        "outputId": "1dce0f88-c4e2-4903-ace1-257d7a75bee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_tXlbiRL27o",
        "outputId": "eeb3cd41-8f2f-4c5a-b053-a24645537002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Training FastText model...\n",
            "✅ FastText training completed!\n",
            "\n",
            "📂 **Embeddings saved at:** FastText_Embeddings.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.models import FastText\n",
        "from tqdm import tqdm\n",
        "\n",
        "# load data\n",
        "file_path = \"Cleaned_Dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#text tokenization method\n",
        "def tokenize_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "        return text.split()\n",
        "    return []\n",
        "\n",
        "df[\"video_title_tokens\"] = df[\"video_title\"].apply(tokenize_text)\n",
        "df[\"video_description_tokens\"] = df[\"video_description\"].apply(tokenize_text)\n",
        "df[\"transcript_tokens\"] = df[\"transcript\"].apply(tokenize_text)\n",
        "\n",
        "# gather texts to train FastText model\n",
        "all_texts = df[\"video_title_tokens\"].tolist() + df[\"video_description_tokens\"].tolist() + df[\"transcript_tokens\"].tolist()\n",
        "\n",
        "# train FastText\n",
        "print(\"⏳ Training FastText model...\")\n",
        "fasttext_model = FastText(sentences=all_texts, vector_size=300, window=5, min_count=2, workers=4, sg=1, epochs=10)\n",
        "print(\"✅ FastText training completed!\")\n",
        "\n",
        "# ✅text to vectors by FastText\n",
        "def get_sentence_embedding(tokens):\n",
        "    vectors = [fasttext_model.wv[word] for word in tokens if word in fasttext_model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(300)\n",
        "\n",
        "\n",
        "df[\"video_title_vector\"] = df[\"video_title_tokens\"].apply(get_sentence_embedding)\n",
        "df[\"video_description_vector\"] = df[\"video_description_tokens\"].apply(get_sentence_embedding)\n",
        "df[\"transcript_vector\"] = df[\"transcript_tokens\"].apply(get_sentence_embedding)\n",
        "\n",
        "# 3 vectors ----> 1 vector\n",
        "df[\"combined_vector\"] = df.apply(lambda row: np.hstack([\n",
        "    row[\"video_title_vector\"],\n",
        "    row[\"video_description_vector\"],\n",
        "    row[\"transcript_vector\"]\n",
        "]), axis=1)\n",
        "\n",
        "# save the data\n",
        "embeddings_file_path = \"FastText_Embeddings.csv\"\n",
        "df[[\"combined_vector\", \"contain_lgbtq\"]].to_csv(embeddings_file_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"\\n📂 **Embeddings saved at:** {embeddings_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-fIWuiwQXZY"
      },
      "source": [
        "##LSTM-CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjpvDWiHW5eW"
      },
      "source": [
        "###Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzKTNi1GRACh",
        "outputId": "0da02366-2120-4fc2-e91e-2e7a7678f4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Number of all values in X: 14404\n",
            "🔹 Number of all values in y: 14404\n",
            "🔍 X_train shape: (11523, 900), y_train shape: (11523,)\n",
            "🔍 y_test shape: (2881, 900), y_test shape: (2881,)\n",
            "✅ Data is now ready for training and testing!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#load data\n",
        "file_path = \"FastText_Embeddings.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#from text to numpy\n",
        "df[\"combined_vector\"] = df[\"combined_vector\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
        "\n",
        "#define x , y\n",
        "X = np.vstack(df[\"combined_vector\"].values)\n",
        "y = df[\"contain_lgbtq\"].values.astype(int)\n",
        "\n",
        "#count x ,y values\n",
        "num_x_values = X.shape[0]\n",
        "num_y_values = len(y)\n",
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#Display the final shape of the data after reshaping\n",
        "\n",
        "print(f\"🔹 Number of all values in X: {num_x_values}\")\n",
        "print(f\"🔹 Number of all values in y: {num_y_values}\")\n",
        "\n",
        "print(f\"🔍 X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"🔍 y_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "print(\"✅ Data is now ready for training and testing!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzk4FfkRS7NO"
      },
      "source": [
        "###Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ6yy2nfVkbV",
        "outputId": "0767aee6-b376-4c16-d5db-71f998d9aede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "Oc8BCJa_lnGw",
        "outputId": "e1782b84-174e-4b67-a328-05165f262356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m384\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m896\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m66,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m5,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,741\u001b[0m (280.24 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,741</span> (280.24 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,613\u001b[0m (279.74 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,613</span> (279.74 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout, BatchNormalization\n",
        "\n",
        "# ✅ Define the improved Hybrid CNN-LSTM Model\n",
        "def HybridTextClassifier(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # ✅ CNN Layer with BatchNormalization\n",
        "    model.add(Conv1D(filters=64, kernel_size=5, activation=\"relu\", input_shape=input_shape))\n",
        "    model.add(BatchNormalization())  # ✅ stabilizes training\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # ✅ LSTM Layer\n",
        "    model.add(LSTM(100, return_sequences=False))\n",
        "\n",
        "    # ✅ Dense Layer + Dropout\n",
        "    model.add(Dense(50, activation=\"relu\"))\n",
        "    model.add(Dropout(0.4))  # ✅ less aggressive dropout\n",
        "\n",
        "    # ✅ Output Layer\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    # ✅ Compile the Model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "# ✅ Create the Model\n",
        "input_shape = (900, 1)\n",
        "model = HybridTextClassifier(input_shape)\n",
        "\n",
        "# ✅ Show Summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpwxex8NY81g"
      },
      "source": [
        "###Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNOBEOYaZLjl",
        "outputId": "a985ef24-4c0c-45f9-9320-08d21cf9bead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 390ms/step - accuracy: 0.8360 - loss: 0.3625 - val_accuracy: 0.7987 - val_loss: 0.5060\n",
            "Epoch 2/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 385ms/step - accuracy: 0.9510 - loss: 0.1422 - val_accuracy: 0.9625 - val_loss: 0.0987\n",
            "Epoch 3/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 388ms/step - accuracy: 0.9648 - loss: 0.1077 - val_accuracy: 0.9733 - val_loss: 0.0780\n",
            "Epoch 4/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 388ms/step - accuracy: 0.9747 - loss: 0.0881 - val_accuracy: 0.9663 - val_loss: 0.0945\n",
            "Epoch 5/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 384ms/step - accuracy: 0.9804 - loss: 0.0629 - val_accuracy: 0.9788 - val_loss: 0.0610\n",
            "Epoch 6/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 387ms/step - accuracy: 0.9728 - loss: 0.0823 - val_accuracy: 0.9760 - val_loss: 0.0753\n",
            "Epoch 7/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 389ms/step - accuracy: 0.9830 - loss: 0.0569 - val_accuracy: 0.9820 - val_loss: 0.0545\n",
            "Epoch 8/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 382ms/step - accuracy: 0.9842 - loss: 0.0505 - val_accuracy: 0.9840 - val_loss: 0.0521\n",
            "Epoch 9/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 385ms/step - accuracy: 0.9843 - loss: 0.0497 - val_accuracy: 0.9514 - val_loss: 0.1223\n",
            "Epoch 10/10\n",
            "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 387ms/step - accuracy: 0.9832 - loss: 0.0508 - val_accuracy: 0.9688 - val_loss: 0.0880\n"
          ]
        }
      ],
      "source": [
        "# ✅ Train the model\n",
        "epochs = 10  # Number of training iterations\n",
        "batch_size = 32 # Number of samples per batch\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tbjQVvyc0IK"
      },
      "source": [
        "###Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVKoEgwvcDYj",
        "outputId": "ddcde056-74ba-4b04-e03c-7f13392788f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 111ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Probabilities (values between 0 and 1)\n",
        "y_pred_probabilities = model.predict(X_test)\n",
        "# Convert probabilities to binary lab\n",
        "y_pred = (y_pred_probabilities > 0.5).astype(\"int32\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S5wjrNiakdn"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZsNbzNxdHlX"
      },
      "source": [
        "###Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU6tHq43bgsX",
        "outputId": "0708d346-8c91-49ac-a695-48976799ae73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 * LSTM + CNN Model  Analysis:*\n",
            "\n",
            "📊 **Total samples:** 14404 \n",
            "\n",
            "***********Train Data **********************\n",
            "📊 *Total Train samples:* 11523\n",
            "✔️ *Training Not LGBT samples:* 5762\n",
            "✔️ *Training LGBT samples:* 5761\n",
            "\n",
            "***********Test Data **********************\n",
            "📊 *Total test samples:* 2881\n",
            "✔️ *Not LGBT samples:* 1441\n",
            "✔️ *LGBT samples:* 1440\n",
            "\n",
            "🎯 **Model Performance:**\n",
            "✅ **Train Accuracy:** 98.58% \n",
            "✅ **Test Accuracy:** 96.88% \n",
            "📈 **Accuracy Gap:** 1.70% 🟢 Good generalization!\n",
            "📉 *Loss Stability Score:* 0.2026\n",
            "📊 *Loss Variation Standard Deviation:* 0.0583\n",
            "\n",
            "📊 **F1-Scores & CHAP Score:**\n",
            "🔄 **F1-Score Not LGBT:** 96.96%\n",
            "🔄 **F1-Score LGBT:** 96.79%\n",
            "⚖ **F1-Score Gap:** 0.17% 🟢 Balanced!\n",
            "🟢 **CHAP Score:** 96.87%\n",
            "\n",
            "🎯 ROC-AUC Score:\n",
            "🟢 ROC-AUC Score: 96.88% \n",
            "\n",
            "✅ *Model is well-generalized! No Overfitting detected.*\n",
            "\n",
            "📊 **Precision & Recall Analysis:**\n",
            "🔍 **Precision (Not LGBT):** 94.53%\n",
            "🔍 **Precision (LGBT):** 99.49%\n",
            "🔍 **Recall (Not LGBT):** 99.51%\n",
            "🔍 **Recall (LGBT):** 94.24%\n",
            "\n",
            "📊 *Confusion Matrix - Raw Values:*\n",
            "╒═════════════════╤══════════════════════╤══════════════════╕\n",
            "│                 │   Predicted Not LGBT │   Predicted LGBT │\n",
            "╞═════════════════╪══════════════════════╪══════════════════╡\n",
            "│ Actual Not LGBT │                 1434 │                7 │\n",
            "├─────────────────┼──────────────────────┼──────────────────┤\n",
            "│ Actual LGBT     │                   83 │             1357 │\n",
            "╘═════════════════╧══════════════════════╧══════════════════╛\n",
            "\n",
            "📊 *Confusion Matrix - Percentage Values:*\n",
            "╒═════════════════╤══════════════════════╤══════════════════╕\n",
            "│                 │   Predicted Not LGBT │   Predicted LGBT │\n",
            "╞═════════════════╪══════════════════════╪══════════════════╡\n",
            "│ Actual Not LGBT │                99.51 │             0.49 │\n",
            "├─────────────────┼──────────────────────┼──────────────────┤\n",
            "│ Actual LGBT     │                 5.76 │            94.24 │\n",
            "╘═════════════════╧══════════════════════╧══════════════════╛\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tabulate import tabulate\n",
        "\n",
        "total_samples = len(y_train) + len(y_test)\n",
        "\n",
        "# ✅ Compute test dataset statistics\n",
        "total_Test_samples = len(y_test)\n",
        "test_positive_samples = np.sum(y_test)\n",
        "test_negative_samples = total_Test_samples - test_positive_samples\n",
        "\n",
        "# ✅ Compute training dataset statistics\n",
        "total_train_samples = len(y_train)\n",
        "train_positive_samples = np.sum(y_train)\n",
        "train_negative_samples = len(y_train) - train_positive_samples\n",
        "\n",
        "# ✅ Compute model accuracy\n",
        "train_accuracy = history.history['accuracy'][-1]\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy_gap = abs(train_accuracy - test_accuracy) * 100\n",
        "\n",
        "# ✅ Analyze loss stability\n",
        "train_loss = history.history['loss']\n",
        "loss_stability = max(train_loss) - min(train_loss)\n",
        "loss_variation = np.std(train_loss)\n",
        "\n",
        "# ✅ Compute confusion matrix & classification report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred, target_names=[\"Not LGBT\", \"LGBT\"], output_dict=True)\n",
        "conf_matrix_percent = conf_matrix.astype(float) / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "# ✅ Compute F1-score & CHAP Score\n",
        "f1_not_lgbt = classification_rep[\"Not LGBT\"][\"f1-score\"] * 100\n",
        "f1_lgbt = classification_rep[\"LGBT\"][\"f1-score\"] * 100\n",
        "f1_gap = abs(f1_not_lgbt - f1_lgbt)\n",
        "\n",
        "chap_score = (f1_not_lgbt + f1_lgbt) / 2  # CHAP Score measures class balance in performance\n",
        "\n",
        "# ✅ Compute ROC-AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred) * 100\n",
        "\n",
        "\n",
        "# ✅ Compute additional metrics\n",
        "precision_not_lgbt = classification_rep[\"Not LGBT\"][\"precision\"] * 100\n",
        "precision_lgbt = classification_rep[\"LGBT\"][\"precision\"] * 100\n",
        "recall_not_lgbt = classification_rep[\"Not LGBT\"][\"recall\"] * 100\n",
        "recall_lgbt = classification_rep[\"LGBT\"][\"recall\"] * 100\n",
        "roc_auc = roc_auc_score(y_test, y_pred) * 100\n",
        "\n",
        "# ✅ Detect overfitting\n",
        "overfitting_detected = False\n",
        "overfitting_reasons = []\n",
        "\n",
        "if accuracy_gap > 5:\n",
        "    overfitting_detected = True\n",
        "    overfitting_reasons.append(f\"⚠ *High Accuracy Gap:* {accuracy_gap:.2f}%\")\n",
        "\n",
        "if loss_stability > 0.4:\n",
        "    overfitting_detected = True\n",
        "    overfitting_reasons.append(f\"⚠ *Unstable Loss Variation:* {loss_stability:.4f}\")\n",
        "\n",
        "if f1_gap > 10:\n",
        "    overfitting_detected = True\n",
        "    overfitting_reasons.append(f\"⚠ *High F1-Score Gap Between Classes:* {f1_gap:.2f}%\")\n",
        "\n",
        "if classification_rep[\"Not LGBT\"][\"recall\"] > 0.95 and classification_rep[\"LGBT\"][\"recall\"] < 0.50:\n",
        "    overfitting_detected = True\n",
        "    overfitting_reasons.append(\"⚠ *Class Bias Detected (Favoring 'Not LGBT').*\")\n",
        "\n",
        "\n",
        "if classification_rep[\"LGBT\"][\"recall\"] > 0.95 and classification_rep[\"Not LGBT\"][\"recall\"] < 0.50:\n",
        "    overfitting_detected = True\n",
        "    overfitting_reasons.append(\"⚠ *Class Bias Detected (Favoring 'Not LGBT').*\")\n",
        "\n",
        "\n",
        "\n",
        "# ✅ Display  analysis\n",
        "print(\"\\n🔍 * LSTM + CNN Model  Analysis:*\\n\")\n",
        "print(f\"📊 **Total samples:** {total_samples} \")\n",
        "print(\"\\n***********Train Data **********************\")\n",
        "print(f\"📊 *Total Train samples:* {total_train_samples}\")\n",
        "print(f\"✔️ *Training Not LGBT samples:* {train_negative_samples}\")\n",
        "print(f\"✔️ *Training LGBT samples:* {train_positive_samples}\")\n",
        "\n",
        "\n",
        "print(\"\\n***********Test Data **********************\")\n",
        "print(f\"📊 *Total test samples:* {total_Test_samples}\")\n",
        "print(f\"✔️ *Not LGBT samples:* {test_negative_samples}\")\n",
        "print(f\"✔️ *LGBT samples:* {test_positive_samples}\")\n",
        "\n",
        "print(\"\\n🎯 **Model Performance:**\")\n",
        "print(f\"✅ **Train Accuracy:** {train_accuracy:.2%} \")\n",
        "print(f\"✅ **Test Accuracy:** {test_accuracy:.2%} \")\n",
        "print(f\"📈 **Accuracy Gap:** {accuracy_gap:.2f}% {'🔴 Overfitting detected!' if accuracy_gap > 5 else '🟢 Good generalization!'}\")\n",
        "print(f\"📉 *Loss Stability Score:* {loss_stability:.4f}\")\n",
        "print(f\"📊 *Loss Variation Standard Deviation:* {loss_variation:.4f}\")\n",
        "\n",
        "print(\"\\n📊 **F1-Scores & CHAP Score:**\")\n",
        "print(f\"🔄 **F1-Score Not LGBT:** {f1_not_lgbt:.2f}%\")\n",
        "print(f\"🔄 **F1-Score LGBT:** {f1_lgbt:.2f}%\")\n",
        "print(f\"⚖ **F1-Score Gap:** {f1_gap:.2f}% {'🔴 Possible class Bias!' if f1_gap > 10 else '🟢 Balanced!'}\")\n",
        "print(f\"🟢 **CHAP Score:** {chap_score:.2f}%\")\n",
        "\n",
        "print(\"\\n🎯 ROC-AUC Score:\")\n",
        "print(f\"🟢 ROC-AUC Score: {roc_auc:.2f}% \")\n",
        "\n",
        "\n",
        "\n",
        "# ✅ Print Overfitting results\n",
        "if overfitting_detected:\n",
        "    print(\"\\n🚨 *Overfitting Detected!* 🚨\")\n",
        "    for reason in overfitting_reasons:\n",
        "        print(reason)\n",
        "else:\n",
        "    print(\"\\n✅ *Model is well-generalized! No Overfitting detected.*\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n📊 **Precision & Recall Analysis:**\")\n",
        "print(f\"🔍 **Precision (Not LGBT):** {precision_not_lgbt:.2f}%\")\n",
        "print(f\"🔍 **Precision (LGBT):** {precision_lgbt:.2f}%\")\n",
        "print(f\"🔍 **Recall (Not LGBT):** {recall_not_lgbt:.2f}%\")\n",
        "print(f\"🔍 **Recall (LGBT):** {recall_lgbt:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# ✅ Display confusion matrix\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"Actual Not LGBT\", \"Actual LGBT\"], columns=[\"Predicted Not LGBT\", \"Predicted LGBT\"])\n",
        "conf_matrix_percent_df = pd.DataFrame(conf_matrix_percent, index=[\"Actual Not LGBT\", \"Actual LGBT\"], columns=[\"Predicted Not LGBT\", \"Predicted LGBT\"])\n",
        "\n",
        "print(\"\\n📊 *Confusion Matrix - Raw Values:*\")\n",
        "print(tabulate(conf_matrix_df, headers='keys', tablefmt='fancy_grid'))\n",
        "print(\"\\n📊 *Confusion Matrix - Percentage Values:*\")\n",
        "print(tabulate(conf_matrix_percent_df.round(2), headers='keys', tablefmt='fancy_grid'))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}